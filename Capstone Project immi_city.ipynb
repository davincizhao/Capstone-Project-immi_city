{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I try to find out in 2006, which cities have TOP 10 population move in ?\n",
    "So I need combine immigration date and iata_code which have location relative to iata code.\n",
    "I choose immigration data from udacity data set sample\n",
    "and extrat IATA code from website:https://www.nationsonline.org/oneworld/IATA_Codes/airport_code_list.htm\n",
    "and get the city name from IATA code that in the immigration. \n",
    "But I found above \"airport_code_csv\" is not include metranpolitan code like \"NYC\". \n",
    "and i search iata_code in wiki website:\"https://en.wikipedia.org/wiki/List_of_airports_by_IATA_code:_\"\n",
    "add get all the new iata code and combine all of them to one table:\n",
    "this table have three columns: iata_id,airport,location\n",
    "### 'iata_id' is 3-alpha letter , string type.\n",
    "\n",
    "### 'airport' is airport name, string type.\n",
    "\n",
    "### 'location' is country name or city name, string type.\n",
    "using python script :\"get_iata_code_from_wiki.py\" that written by myself.\n",
    "\n",
    " ### I extracted i94yr: as year,i94mon: as month,i94cit: as from_city,i94port: as to_city, admnum: as total_immi_num.\n",
    "\n",
    "\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fname_i = 'immigration_data_sample.csv'\n",
    "df = pd.read_csv(fname_i)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- cicid: string (nullable = true)\n",
      " |-- i94yr: string (nullable = true)\n",
      " |-- i94mon: string (nullable = true)\n",
      " |-- i94cit: string (nullable = true)\n",
      " |-- i94res: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: string (nullable = true)\n",
      " |-- i94mode: string (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: string (nullable = true)\n",
      " |-- i94bir: string (nullable = true)\n",
      " |-- i94visa: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: string (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the sparksession\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "#read and load golbal land temperature by city dataset in csv format\n",
    "df_sp_immi  = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"immigration_data_sample.csv\")\n",
    "df_sp_immi.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### I extracted i94yr: as year,i94mon: as month,i94cit: as from_city,i94port: as to_city, admnum: as total_immi_num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates row\n",
    "df_immi_spark=df_sp_immi.dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immi_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read and load \"\"airport-codes_csv.csv\"\"\n",
    "df_iata_default  = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"airport-codes_csv.csv\")\n",
    "df_iata_default.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
      "| 00AS|small_airport|      Fulton Airport|        1100|       NA|         US|     US-OK|        Alex|    00AS|     null|      00AS|-97.8180194, 34.9...|\n",
      "| 00AZ|small_airport|      Cordes Airport|        3810|       NA|         US|     US-AZ|      Cordes|    00AZ|     null|      00AZ|-112.165000915527...|\n",
      "| 00CA|small_airport|Goldstone /Gts/ A...|        3038|       NA|         US|     US-CA|     Barstow|    00CA|     null|      00CA|-116.888000488, 3...|\n",
      "| 00CL|small_airport| Williams Ag Airport|          87|       NA|         US|     US-CA|       Biggs|    00CL|     null|      00CL|-121.763427, 39.4...|\n",
      "| 00CN|     heliport|Kitchen Creek Hel...|        3350|       NA|         US|     US-CA| Pine Valley|    00CN|     null|      00CN|-116.4597417, 32....|\n",
      "| 00CO|       closed|          Cass Field|        4830|       NA|         US|     US-CO|  Briggsdale|    null|     null|      null|-104.344002, 40.6...|\n",
      "| 00FA|small_airport| Grass Patch Airport|          53|       NA|         US|     US-FL|    Bushnell|    00FA|     null|      00FA|-82.2190017700195...|\n",
      "| 00FD|     heliport|  Ringhaver Heliport|          25|       NA|         US|     US-FL|   Riverview|    00FD|     null|      00FD|-82.3453979492187...|\n",
      "| 00FL|small_airport|   River Oak Airport|          35|       NA|         US|     US-FL|  Okeechobee|    00FL|     null|      00FL|-80.9692001342773...|\n",
      "| 00GA|small_airport|    Lt World Airport|         700|       NA|         US|     US-GA|    Lithonia|    00GA|     null|      00GA|-84.0682983398437...|\n",
      "| 00GE|     heliport|    Caffrey Heliport|         957|       NA|         US|     US-GA|       Hiram|    00GE|     null|      00GE|-84.7339019775390...|\n",
      "| 00HI|     heliport|  Kaupulehu Heliport|          43|       NA|         US|     US-HI| Kailua/Kona|    00HI|     null|      00HI|-155.980233, 19.8...|\n",
      "| 00ID|small_airport|Delta Shores Airport|        2064|       NA|         US|     US-ID|  Clark Fork|    00ID|     null|      00ID|-116.213996887207...|\n",
      "| 00IG|small_airport|       Goltl Airport|        3359|       NA|         US|     US-KS|    McDonald|    00IG|     null|      00IG|-101.395994, 39.7...|\n",
      "| 00II|     heliport|Bailey Generation...|         600|       NA|         US|     US-IN|  Chesterton|    00II|     null|      00II|-87.122802734375,...|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_iata_default.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55075"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iata_default.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- IATA_CODE: string (nullable = true)\n",
      " |-- ICAO_CODE: string (nullable = true)\n",
      " |-- airport: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read and load golbal land temperature by city dataset in csv format\n",
    "df_iata_wiki  = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"iata_code1104.csv\")\n",
    "df_iata_wiki.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------------------+\n",
      "|IATA_CODE|ICAO_CODE|             airport|            Location|\n",
      "+---------+---------+--------------------+--------------------+\n",
      "|      AAA|     NTGA|        Anaa Airport|Anaa, Tuamotus, F...|\n",
      "|      AAB|     YARY|    Arrabury Airport|Arrabury, Queensl...|\n",
      "|      AAC|     HEAR|El Arish Internat...|     El Arish, Egypt|\n",
      "|      AAD|     null|       Adado Airport|Adado (Cadaado), ...|\n",
      "|      AAE|     DABB|Rabah Bitat Airpo...|     Annaba, Algeria|\n",
      "|      AAF|     KAAF|Apalachicola Regi...|Apalachicola, Flo...|\n",
      "|      AAG|     SSYA|     Arapoti Airport|Arapoti, Paraná, ...|\n",
      "|      AAH|     EDKA|   Merzbrück Airport|Aachen, North Rhi...|\n",
      "|      AAI|     SWRA|     Arraias Airport|Arraias, Tocantin...|\n",
      "|      AAJ|     SMCA|     Cayana Airstrip|  Awaradam, Suriname|\n",
      "|      AAK|     NGUK|     Aranuka Airport|   Aranuka, Kiribati|\n",
      "|      AAL|     EKYT|     Aalborg Airport|    Aalborg, Denmark|\n",
      "|      AAM|     FAMD|   Mala Mala Airport|Mala Mala, South ...|\n",
      "|      AAN|     OMAL|Al Ain Internatio...|Al Ain, United Ar...|\n",
      "|      AAO|     SVAN|       Anaco Airport|    Anaco, Venezuela|\n",
      "|      AAP|     WALS|Aji Pangeran Tume...|Samarinda, East K...|\n",
      "|      AAQ|     URKA|       Anapa Airport|Anapa, Krasnodar ...|\n",
      "|      AAR|     EKAH|      Aarhus Airport|     Aarhus, Denmark|\n",
      "|      AAS|     null|  Apalapsili Airport|Apalapsili, Indon...|\n",
      "|      AAT|     ZWAT|       Altay Airport|Altay, Xinjiang, ...|\n",
      "+---------+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_iata_wiki.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12872"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iata_wiki.dropDuplicates()\n",
    "df_iata_wiki.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At first,I use pandas to identify data quality issues,like missing values,duplicate data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9010"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform spark dataframe to pandas dataframe\n",
    "# because airport-codes_csv.csv is not good data , so i choose my own data iata_code1104.csv from wiki website, it is clearer and better than airport-codes_csv.csv\n",
    "pd_iata_wiki = df_iata_wiki.toPandas()\n",
    "# drop all the duplicate \"iata-code\"\n",
    "drop_d=pd_iata_wiki.drop_duplicates('IATA_CODE')\n",
    "# transform pandas dataframe back to spark dataframe\n",
    "sp_df_wiki=spark.createDataFrame(drop_d)\n",
    "# count the total row number\n",
    "sp_df_wiki.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fact Table\n",
    "1.immigration population in world.\n",
    "              _c0 AS id,\n",
    "              i94yr AS year, \n",
    "              i94mon AS month,\n",
    "              i94cit AS from_city,\n",
    "              i94port AS iata_id,\n",
    "              CAST(admnum AS bigint) AS total_immi_num \n",
    "#### Dimension Tables\n",
    "2.location\n",
    "iata_id,airport,location\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the immigration data pipeline to create the data model.\n",
    "df_immi_spark.createOrReplaceTempView(\"immi\")\n",
    "out=spark.sql('''SELECT DISTINCT\n",
    "              _c0 AS id,\n",
    "              i94yr AS year, \n",
    "              i94mon AS month,\n",
    "              i94cit AS from_city,\n",
    "              i94port AS to_city,\n",
    "              CAST(admnum AS bigint) AS total_immi_num \n",
    "              FROM immi''')\n",
    "out.write.parquet(\"./output/immi0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df_wiki.createOrReplaceTempView(\"location_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|iata_id|             airport|            location|\n",
      "+-------+--------------------+--------------------+\n",
      "|    AGO|Magnolia Municipa...|Magnolia, Arkansa...|\n",
      "|    BDT|   Gbadolite Airport|Gbadolite, Democr...|\n",
      "|    BGA|Palonegro Interna...|Bucaramanga, Colo...|\n",
      "|    BIO|      Bilbao Airport|Bilbao, Basque Co...|\n",
      "|    BWN|Brunei Internatio...|Bandar Seri Begaw...|\n",
      "|    CLJ|Cluj-Napoca Inter...|Cluj-Napoca, Romania|\n",
      "|    CYL|     Coyoles Airport|   Coyoles, Honduras|\n",
      "|    DMN|Deming Municipal ...|Deming, New Mexic...|\n",
      "|    FUG|Fuyang Xiguan Air...|Fuyang, Anhui, China|\n",
      "|    GHF| Giebelstadt Airport|Giebelstadt, Bava...|\n",
      "|    IFJ|  Ísafjörður Airport| Ísafjörður, Iceland|\n",
      "|    KMZ|       Kaoma Airport|       Kaoma, Zambia|\n",
      "|    KNZ|     Kéniéba Airport|       Kéniéba, Mali|\n",
      "|    MIZ|  Mainoru Airport[1]|Mainoru, Northern...|\n",
      "|    MNN|Marion Municipal ...|Marion, Ohio, Uni...|\n",
      "|    MQL|     Mildura Airport|Mildura, Victoria...|\n",
      "|    MRF|Marfa Municipal A...|Marfa, Texas, Uni...|\n",
      "|    MVB|M'Vengue El Hadj ...|  Franceville, Gabon|\n",
      "|    MVM|Kayenta Airport (...|Kayenta, Arizona,...|\n",
      "|    MYI|Murray Island Air...|Murray Island, Qu...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "location= spark.sql('''select DISTINCT IATA_CODE AS iata_id, \n",
    "                    airport,\n",
    "                    Location AS location\n",
    "                    FROM location_view\n",
    "                \n",
    "                    ''')\n",
    "location.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- iata_id: string (nullable = true)\n",
      " |-- airport: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "location.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add iata code from wiki 12870 codes. to \"./output/location.parquet\" \n",
    "location.write.mode(\"Append\").parquet(\"./output/location.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iata model date from parquet. and save to location_view.\n",
    "location_view=spark.read.parquet(\"./output/location.parquet\")\n",
    "location_view.createOrReplaceTempView(\"location_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|to_city|         total|\n",
      "+-------+--------------+\n",
      "|    NYC|10846125450235|\n",
      "|    MIA| 8922547681245|\n",
      "|    LOS| 6965071195933|\n",
      "|    SFR| 3591412487120|\n",
      "|    CHI| 3020403711605|\n",
      "|    ORL| 2736974886745|\n",
      "|    HOU| 2728330237345|\n",
      "|    ATL| 2669580186622|\n",
      "|    NEW| 2589234201821|\n",
      "|    HHW| 2461775306030|\n",
      "+-------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# base on the immigration model ,get top 10 immigration population cities\n",
    "immi_num=spark.read.parquet(\"./output/immi2.parquet\")\n",
    "immi_num.createOrReplaceTempView(\"immi_table\")\n",
    "sorted_city= spark.sql('''\n",
    "\n",
    "                    SELECT to_city,\n",
    "                    SUM(total_immi_num) AS total\n",
    "                    FROM immi_table\n",
    "                    GROUP BY to_city\n",
    "                    ORDER BY total DESC\n",
    "\n",
    "                    ''')\n",
    "sorted_city.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tempview sorted city population\n",
    "sorted_city.createOrReplaceTempView(\"sorted_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 immigration cities which immigration move in\n",
    "answer=spark.sql('''SELECT DISTINCT\n",
    "                    s.to_city,\n",
    "                    l.location,\n",
    "                    l.airport,\n",
    "                    s.total\n",
    "                    FROM sorted_view as s\n",
    "                    JOIN location_view AS l\n",
    "                    WHERE s.to_city=l.iata_id\n",
    "                    ORDER BY s.total DESC\n",
    "                    ''')     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------+\n",
      "|to_city|            location|             airport|         total|\n",
      "+-------+--------------------+--------------------+--------------+\n",
      "|    NYC|New York City, Ne...|  metropolitan area2|10846125450235|\n",
      "|    MIA|Miami, Florida, U...|Miami Internation...| 8922547681245|\n",
      "|    LOS|      Lagos, Nigeria|Murtala Muhammed ...| 6965071195933|\n",
      "|    CHI|Chicago, Illinois...|  metropolitan area2| 3020403711605|\n",
      "|    ORL|Orlando, Florida,...|Orlando Executive...| 2736974886745|\n",
      "|    HOU|Houston, Texas, U...|William P. Hobby ...| 2728330237345|\n",
      "|    ATL|Atlanta, Georgia,...|Hartsfield–Jackso...| 2669580186622|\n",
      "|    NEW|New Orleans, Loui...|   Lakefront Airport| 2589234201821|\n",
      "|    WAS|Washington, D.C.,...|  metropolitan area1| 1765844128444|\n",
      "|    DAL|Dallas, Texas, Un...|   Dallas Love Field| 1317476983970|\n",
      "+-------+--------------------+--------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# top 10 cities immigration moving into.\n",
    "answer.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform quality checks here\n",
    "# As you can see above, sorted_city top 10 citits is different from the answer top 10 cities\n",
    "\n",
    "### from immigration data : top 10 is \n",
    "+-------+--------------+\n",
    "|to_city|         total|\n",
    "+-------+--------------+\n",
    "|    NYC|10846125450235|\n",
    "|    MIA| 8922547681245|\n",
    "|    LOS| 6965071195933|\n",
    "|    SFR| 3591412487120|\n",
    "|    CHI| 3020403711605|\n",
    "|    ORL| 2736974886745|\n",
    "|    HOU| 2728330237345|\n",
    "|    ATL| 2669580186622|\n",
    "|    NEW| 2589234201821|\n",
    "|    HHW| 2461775306030|\n",
    "+-------+--------------+\n",
    "\n",
    "### but after combine the two tables: fact table and demension. the result is :\n",
    "+-------+--------------------+--------------------+--------------+\n",
    "|to_city|            location|             airport|         total|\n",
    "+-------+--------------------+--------------------+--------------+\n",
    "|    NYC|New York City, Ne...|  metropolitan area2|10846125450235|\n",
    "|    MIA|Miami, Florida, U...|Miami Internation...| 8922547681245|\n",
    "|    LOS|      Lagos, Nigeria|Murtala Muhammed ...| 6965071195933|\n",
    "|    CHI|Chicago, Illinois...|  metropolitan area2| 3020403711605|\n",
    "|    ORL|Orlando, Florida,...|Orlando Executive...| 2736974886745|\n",
    "|    HOU|Houston, Texas, U...|William P. Hobby ...| 2728330237345|\n",
    "|    ATL|Atlanta, Georgia,...|Hartsfield–Jackso...| 2669580186622|\n",
    "|    NEW|New Orleans, Loui...|   Lakefront Airport| 2589234201821|\n",
    "|    WAS|Washington, D.C.,...|  metropolitan area1| 1765844128444|\n",
    "|    DAL|Dallas, Texas, Un...|   Dallas Love Field| 1317476983970|\n",
    "+-------+--------------------+--------------------+--------------+\n",
    "\n",
    "the result is wrong ,because there is miss city \"SFR\" and \"HHW\". So more iata code data need to be collected, and then Append to \"./output/location.parquet\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more data into location.parquet , and then clean the duplicate row.\n",
    "\n",
    "backup_iata=spark.read.parquet(\"./output/iata_table2.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------+\n",
      "|iata_id|             airport|location|\n",
      "+-------+--------------------+--------+\n",
      "|    SFR|San Fernando Airport|      US|\n",
      "+-------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backup_iata.select('iata_id','airport','location').where(backup_iata['iata_id']=='SFR').show()\n",
    "# So i load the backup iata code date from iata_table2.parquet and append to \"./output/location.parquet\"\n",
    "backup_iata.write.mode(\"Append\").parquet(\"./output/location.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the clean data process again , clean duplicated row in iata_id, because treat \"iata code\" as primary key\n",
    "# read \"./output/location.parquet\" to spark data frame \n",
    "update_location= spark.read.parquet(\"./output/location.parquet\")\n",
    "dropd = update_location.dropDuplicates()\n",
    "# transfer the spark dataframe to pandas dataframe \n",
    "df=dropd.toPandas()\n",
    "# Using dataframe methods to clean duplicates iata code\n",
    "iata_code=df.drop_duplicates('iata_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9422"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transfer the Pandas data frame back to spark data frame\n",
    "sp_df_location=spark.createDataFrame(iata_code)\n",
    "sp_df_location.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- iata_id: string (nullable = true)\n",
      " |-- airport: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sp_df_location.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df_location.createOrReplaceTempView(\"updated_location_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 immigration cities which immigration move in\n",
    "final_answer=spark.sql('''SELECT DISTINCT\n",
    "                    s.to_city,\n",
    "                    l.location,\n",
    "                    l.airport,\n",
    "                    s.total\n",
    "                    FROM sorted_view as s\n",
    "                    JOIN updated_location_view AS l\n",
    "                    WHERE s.to_city=l.iata_id\n",
    "                    ORDER BY s.total DESC\n",
    "                    ''')     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------+\n",
      "|to_city|            location|             airport|         total|\n",
      "+-------+--------------------+--------------------+--------------+\n",
      "|    NYC|New York City, Ne...|  metropolitan area2|10846125450235|\n",
      "|    MIA|Miami, Florida, U...|Miami Internation...| 8922547681245|\n",
      "|    LOS|      Lagos, Nigeria|Murtala Muhammed ...| 6965071195933|\n",
      "|    SFR|                  US|San Fernando Airport| 3591412487120|\n",
      "|    CHI|Chicago, Illinois...|  metropolitan area2| 3020403711605|\n",
      "|    ORL|                  US|Orlando Executive...| 2736974886745|\n",
      "|    HOU|Houston, Texas, U...|William P. Hobby ...| 2728330237345|\n",
      "|    ATL|Atlanta, Georgia,...|Hartsfield–Jackso...| 2669580186622|\n",
      "|    NEW|New Orleans, Loui...|   Lakefront Airport| 2589234201821|\n",
      "|    WAS|Washington, D.C.,...|  metropolitan area1| 1765844128444|\n",
      "+-------+--------------------+--------------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_answer.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you can see above, the 10th city is wrong ,it must be \"HHW\", not \"WAS\" Washington, D.C.\n",
    "But I haven't found the result when I searched \"HHW\" in iata code in wiki websit,\n",
    "So I infer the \"HHW\" is wrong data ,  maybe it is \"KHHW \"in ICAO CODE. It represents \"KHHW Stan Stamper Municipal Airport (FAA: HHW) Hugo, Oklahoma, United States\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fact table: immigration data set, from udacity data set sample.\n",
    "\n",
    "### I extracted \n",
    "### i94yr: as year, can be cast as datetime type\n",
    "### i94mon: as month, can be cast as datetime type\n",
    "### i94cit: as from_city, \"3 digit Numeric code ISO 3166 codes for each country.\" \n",
    "### i94port: as to_city, \"alpha-3 code character,IATA CODE\" string type\n",
    "### admnum: as total_immi_num. bigint type\n",
    "\n",
    "## Demenstion table: using python script :\"get_iata_code_from_wiki.py\" extract from iata code wiki website.\n",
    "\n",
    "### 'iata_id' is 3-alpha letter , string type.\n",
    "\n",
    "### 'airport' is airport name, string type.\n",
    "\n",
    "### 'location' is country name or city name, string type.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. tool sets: pandas ,pyspark,pyspark.sql, bs4, BeautifulSoup,requests, csv,time\n",
    "2. I think the data should be updated every 6 months, because more people immigration frequently.\n",
    "3. if the data was increased by 100x. use AWS S3 as stage store. and run the spark in the AWS cloud cluster to accelerate the loading data speed and caculation.\n",
    "4. if the data populates a dashboard that must be updated on a daily basis by 7am every day, it is better to use airflow to make populates automative.\n",
    "5. if The database needed to be accessed by 100+ people. it is better to use Cassandra database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
